{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"start run script forecast_today.py\")\n",
    "print(datetime.datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"))\n",
    "## Create engine and connect to server\n",
    "engine = create_engine(\"postgresql+psycopg2://username:password@host:5432/db\")\n",
    "connection = engine.connect()\n",
    "## Query data from database\n",
    "data = pd.read_sql_query(\"\"\"SELECT (\"createdTime\" + interval '7 hours') as \"createdTime\", \"deliverFromProvinceId\" as \"Location\" \n",
    "                                  FROM \"DeliveryOrder\" \n",
    "                                  WHERE (\"deliverFromProvinceId\" =9 OR \"deliverFromProvinceId\" =80)\n",
    "                                  and DATE(\"createdTime\" + interval '7 hours') < DATE(now() + interval '7 hours') \n",
    "                                    and DATE(\"createdTime\" + interval '7 hours') > DATE('1/1/2018')\"\"\" , connection)\n",
    "\n",
    "users_df = pd.read_sql_query(\"\"\"SELECT id,Date(\"firstUsingService\" + interval '7 hours') as to_date \n",
    "                                     FROM public.\"Users\" \n",
    "                                        where realm='customer'\"\"\", connection)\n",
    "\n",
    "\n",
    "\n",
    "users_df.to_date = pd.to_datetime(users_df.to_date)\n",
    "\n",
    "\n",
    "users_df.head()\n",
    "\n",
    "\n",
    "\n",
    "salesman = pd.read_excel(\"ShippoSales.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # END OF LOADING DATA\n",
    "# ## PREPROCESSING DATA BELOW\n",
    "\n",
    "\n",
    "\n",
    "## Rule Chia ca \n",
    "def rule(time):\n",
    "    hour = time.hour\n",
    "    if hour < 6:\n",
    "        return (0,0)\n",
    "    elif 6<= hour < 11:\n",
    "        return (0,1)\n",
    "    elif 11<= hour < 16:\n",
    "        return (0,2)\n",
    "    elif 16 <= hour < 19:\n",
    "        return (0,3)\n",
    "    else:\n",
    "        return (1, 0)\n",
    "\n",
    "## Get active users\n",
    "def get_active_users_last_month(date):\n",
    "    active_order = users_df[np.logical_and(users_df.to_date > date - pd.DateOffset(days = 7), users_df.to_date < date)]\n",
    "    active_user = active_order.customerId.nunique()\n",
    "    return active_user\n",
    "\n",
    "def active_users(row):\n",
    "    row[\"active_user\"] = get_active_users_last_month(row['ngay_giao'])\n",
    "    return row\n",
    "\n",
    "## Filter holidays\n",
    "def holiday(row):\n",
    "    if row['ngay_giao'] in holidays:\n",
    "        row['demand'] = np.nan\n",
    "    for i in range(6):\n",
    "        row['before_holiday'] = 0\n",
    "        if row['ngay_giao'] + pd.DateOffset(days = i+1) in holidays and row['ngay_giao'] + pd.DateOffset(days = i+1) not in sundays:\n",
    "            row['before_holiday'] = 7-i\n",
    "            break\n",
    "    return row\n",
    "\n",
    "def saturday(row):\n",
    "    if row.ngay_giao in sats and row.ca_giao > 1:\n",
    "        row['demand'] = np.nan\n",
    "    return row\n",
    "## Get # new users last week\n",
    "def get_new_users_last_month(date):\n",
    "    temp = users_df[np.logical_and(users_df.to_date > date - pd.DateOffset(days = 7), users_df.to_date < date)]\n",
    "    new_users = temp.shape[0]\n",
    "    return new_users\n",
    "def new_users(row):\n",
    "    row[\"new_users\"] = get_new_users_last_month(row['ngay_giao'])\n",
    "    return row\n",
    "    \n",
    "\n",
    "## Handle Missing data:\n",
    "def get_date(d):\n",
    "    return pd.to_datetime(\"{}/{}/{}\".format(d[:2], d[2:4], d[4:8]))\n",
    "def subtract_week(d):\n",
    "    date = get_date(d)\n",
    "    date = date - pd.DateOffset(days = 7)\n",
    "    temp = date.strftime(\"%m%d%Y\") + d[-1]\n",
    "    return temp\n",
    "def subtract_month(d):\n",
    "    date = get_date(d)\n",
    "    date = date - pd.DateOffset(months = 1)\n",
    "    temp = date.strftime(\"%m%d%Y\") + d[-1]\n",
    "    return temp\n",
    "def subtract_day(d):\n",
    "    date= get_date(d)\n",
    "    date = date - pd.DateOffset(days=1)\n",
    "    temp = date.strftime(\"%m%d%Y\") + d[-1]\n",
    "    return temp\n",
    "# def estimate(x, i):\n",
    "#     a = 1.00804\n",
    "#     b = 6.7392487\n",
    "#     res = a*x +b\n",
    "#     if i == 0:\n",
    "#         return float(res)\n",
    "#     else:\n",
    "#         for e in range (i):\n",
    "#             res = a*res + b\n",
    "#         return float(res)\n",
    "\n",
    "def fill_na_custom(row):\n",
    "    if math.isnan(row.demand):\n",
    "        row[\"demand\"] = row[\"fill_data\"]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## GENERATE HOLIDAYS:\n",
    "\n",
    "\n",
    "tet2016 = [datetime.date(2017,1,22) + datetime.timedelta(days=x) for x in range(0, 22)]\n",
    "tet2017 = [datetime.date(2018,2,10) + datetime.timedelta(days=x) for x in range(0, 21)]\n",
    "nghile2017 = [datetime.date(2016, 12, 31), datetime.date(2017, 1, 2), datetime.date(2017, 1, 1), datetime.date(2017,4, 16),            datetime.date(2017, 4, 29), datetime.date(2017, 4, 30), datetime.date(2017, 5, 1), datetime.date(2017, 5, 2), datetime.date(2017, 9, 2),             datetime.date(2017, 9, 3), datetime.date(2017, 9, 4)]\n",
    "nghile2018 = [datetime.date(2017, 12, 30),datetime.date(2017, 12, 31), datetime.date(2018, 1, 1),             datetime.date(2018, 4, 25), datetime.date(2018, 4, 28), datetime.date(2018, 4, 29),             datetime.date(2018, 4, 30), datetime.date(2018, 5, 1), datetime.date(2018, 9, 1), datetime.date(2018, 9, 2), datetime.date(2018, 9, 3)]\n",
    "nghile2019 = [datetime.date(2018,1,31), datetime.date(2019,1,1), datetime.date(2019,1,30), datetime.date(2019,1,31), datetime.date(2019,2,1),datetime.date(2019,2,2), datetime.date(2019,2,3), datetime.date(2019,2,4),\n",
    "              datetime.date(2019,2,5), datetime.date(2019,2,6), datetime.date(2019,2,7), datetime.date(2019,2,8), datetime.date(2019,2,9), datetime.date(2019,2,10), datetime.date(2019,2,11), datetime.date(2019,2,12), datetime.date(2019,2,13),\n",
    "              datetime.date(2019,2,14), datetime.date(2019,2,15), datetime.date(2019,2,16)]\n",
    "\n",
    "sundays = []\n",
    "def allsundays(year):\n",
    "   d = datetime.date(year, 1, 1)                    # January 1st\n",
    "   d += datetime.timedelta(days = 6 - d.weekday())  # First Sunday\n",
    "   while d.year == year:\n",
    "      yield d\n",
    "      d += datetime.timedelta(days = 7)\n",
    "    \n",
    "def allsats(year):\n",
    "   d = datetime.date(year, 1, 1)                    # January 1st\n",
    "   d += datetime.timedelta(days = 5 - d.weekday())  # First Sunday\n",
    "   while d.year == year:\n",
    "      yield d\n",
    "      d += datetime.timedelta(days = 7)\n",
    "sundays = [d for d in allsundays(2016)] + [d for d in allsundays(2017)] + [d for d in allsundays(2018)]\n",
    "holidays = tet2016 + tet2017 + nghile2017 + nghile2018 + nghile2019\n",
    "holidays = [np.datetime64(i) for i in holidays]\n",
    "sundays = [np.datetime64(i) for i in sundays]\n",
    "sats = [d for d in allsats(2016)] + [d for d in allsats(2017)] + [d for d in allsats(2018)]\n",
    "sats = [np.datetime64(i) for i in sats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing data\n",
    "## Convert to date time type\n",
    "data.createdTime = pd.to_datetime(data.createdTime)\n",
    "## Ap dung Rule chia ca:\n",
    "result = np.array([rule(xi) for xi in data.createdTime])\n",
    "## Them cot ngay_giao\n",
    "data[\"ngay_giao\"] = data.createdTime.values.astype(\"datetime64[D]\")+ result[:,0].astype(\"timedelta64[D]\")\n",
    "## Them cot ca_giao\n",
    "data[\"ca_giao\"] = result[:,1]\n",
    "# data = data[data.ca_giao != 0]\n",
    "# data = data[data.ngay_giao > pd.to_datetime(\"2018/01/01\")]\n",
    "\n",
    "HN_sales = salesman.iloc[0].to_dict()\n",
    "HCM_sales = salesman.iloc[1].to_dict()\n",
    "data_hn = data[data.Location == 9]\n",
    "data_hcm = data[data.Location== 80]\n",
    "data_hn[\"temp\"] = data_hn.createdTime.dt.year.astype(str) + \"-\" +data_hn.createdTime.dt.month.astype(str) \n",
    "data_hcm[\"temp\"] = data_hcm.createdTime.dt.year.astype(str) + \"-\" +data_hcm.createdTime.dt.month.astype(str)\n",
    "data_hn[\"sales\"] = data_hn.temp.map(HN_sales).astype(float)\n",
    "data_hcm[\"sales\"] = data_hcm.temp.map(HCM_sales).astype(float)\n",
    "del data_hn['Location']\n",
    "del data_hn['temp']\n",
    "del data_hcm['temp']\n",
    "del data_hcm['Location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data for training model:\n",
    "model_data = []\n",
    "demand_dicts = []\n",
    "for df in [data_hn, data_hcm]:\n",
    "    modelling_data = pd.DataFrame()\n",
    "    modelling_data = df.groupby(by = [\"ngay_giao\",\"ca_giao\"]).agg({'createdTime':'count','sales':'mean'})\n",
    "    modelling_data.columns = ['demand',\"sales\"]\n",
    "    modelling_data = modelling_data.reset_index()\n",
    "    modelling_data = modelling_data.apply(holiday, axis = 1)\n",
    "#     modelling_data = modelling_data.apply(saturday, axis = 1)\n",
    "    modelling_data = modelling_data.dropna()\n",
    "    modelling_data[\"ngay_ca\"] = modelling_data.ngay_giao.dt.strftime(\"%m%d%Y\") + modelling_data.ca_giao.astype(str)\n",
    "    modelling_data = modelling_data.apply(new_users, axis = 1)\n",
    "\n",
    "    demand_dict = dict(zip(modelling_data.ngay_ca, modelling_data.demand))\n",
    "    demand_dicts.append(demand_dict)\n",
    "    modelling_data = modelling_data.set_index(\"ngay_ca\")\n",
    "\n",
    "    demand_lag_week = pd.DataFrame()\n",
    "    demand_lag_week[\"ngay_giao\"] = modelling_data.ngay_giao - pd.DateOffset(days = 7)\n",
    "    demand_lag_week[\"ca_giao\"] = modelling_data.ca_giao\n",
    "    demand_lag_week[\"ngay_ca_1\"]= demand_lag_week.ngay_giao.dt.strftime(\"%m%d%Y\") + demand_lag_week.ca_giao.astype(str)\n",
    "    demand_lag_week[\"demand\"] = demand_lag_week.ngay_ca_1.map(demand_dict)\n",
    "\n",
    "    demand_lag_2week = pd.DataFrame()\n",
    "    demand_lag_2week[\"ngay_giao\"] = modelling_data.ngay_giao - pd.DateOffset(days = 14)\n",
    "    demand_lag_2week[\"ca_giao\"] = modelling_data.ca_giao\n",
    "    demand_lag_2week[\"ngay_ca_1\"]= demand_lag_2week.ngay_giao.dt.strftime(\"%m%d%Y\") + demand_lag_2week.ca_giao.astype(str)\n",
    "    demand_lag_2week[\"demand\"] = demand_lag_2week.ngay_ca_1.map(demand_dict)\n",
    "    \n",
    "    demand_lag_3week = pd.DataFrame()\n",
    "    demand_lag_3week[\"ngay_giao\"] = modelling_data.ngay_giao - pd.DateOffset(days = 21)\n",
    "    demand_lag_3week[\"ca_giao\"] = modelling_data.ca_giao\n",
    "    demand_lag_3week[\"ngay_ca_1\"]= demand_lag_3week.ngay_giao.dt.strftime(\"%m%d%Y\") + demand_lag_3week.ca_giao.astype(str)\n",
    "    demand_lag_3week[\"demand\"] = demand_lag_3week.ngay_ca_1.map(demand_dict)\n",
    "\n",
    "    demand_lag_month = pd.DataFrame()\n",
    "    demand_lag_month[\"ngay_giao\"] = modelling_data.ngay_giao - pd.DateOffset(months = 1)\n",
    "    demand_lag_month[\"ca_giao\"] = modelling_data.ca_giao\n",
    "    demand_lag_month[\"ngay_ca_1\"] = demand_lag_month.ngay_giao.dt.strftime(\"%m%d%Y\") + demand_lag_month.ca_giao.astype(str)\n",
    "    demand_lag_month[\"demand\"] = demand_lag_month.ngay_ca_1.map(demand_dict)\n",
    "\n",
    "    demand_lag_day = pd.DataFrame()\n",
    "    demand_lag_day[\"ngay_giao\"] = modelling_data.ngay_giao - pd.DateOffset(days = 1)\n",
    "    demand_lag_day[\"ca_giao\"] = modelling_data.ca_giao\n",
    "    demand_lag_day[\"ngay_ca_1\"] = demand_lag_day.ngay_giao.dt.strftime(\"%m%d%Y\") + demand_lag_day.ca_giao.astype(str)\n",
    "    demand_lag_day[\"demand\"] = demand_lag_day.ngay_ca_1.map(demand_dict)\n",
    "    \n",
    "    \n",
    "    \n",
    "    demand_lag_ca1 = pd.DataFrame()\n",
    "    demand_lag_ca1[\"ngay_giao\"] = modelling_data.ngay_giao\n",
    "    demand_lag_ca1[\"ca_giao\"] = modelling_data.ca_giao - 1\n",
    "    demand_lag_ca1[\"ngay_ca_1\"] = demand_lag_ca1.ngay_giao.dt.strftime(\"%m%d%Y\") + demand_lag_ca1.ca_giao.astype(str)\n",
    "    demand_lag_ca1[\"demand\"] = demand_lag_ca1.ngay_ca_1.map(demand_dict)\n",
    "    ## FILL NA FOR LAG WEEK\n",
    "    thresh_hold = np.min(modelling_data.ngay_giao)\n",
    "    fill_data =[]\n",
    "    null_demand_lag_week = demand_lag_week[(demand_lag_week.demand).isnull()]\n",
    "    for index,row in null_demand_lag_week.iterrows():\n",
    "        d = row[\"ngay_ca_1\"]\n",
    "        d = subtract_week(d)\n",
    "        available_data = np.nan\n",
    "        while get_date(d) > thresh_hold and math.isnan(available_data):\n",
    "            i = 0\n",
    "            try:\n",
    "                available_data = modelling_data.demand.loc[d]\n",
    "            except:\n",
    "                available_data = np.nan\n",
    "            d = subtract_week(d)\n",
    "            i = i+1\n",
    "        fill_data.append(available_data)    \n",
    "    null_demand_lag_week['fill_data'] = fill_data\n",
    "    fill_data = null_demand_lag_week['fill_data']\n",
    "    fill_data = fill_data.reset_index()\n",
    "    demand_lag_week = demand_lag_week.reset_index()\n",
    "    demand_lag_week = pd.merge(demand_lag_week, fill_data, how=\"left\", on=\"ngay_ca\")\n",
    "    demand_lag_week = demand_lag_week.set_index(\"ngay_ca\")\n",
    "    demand_lag_week = demand_lag_week.apply(fill_na_custom, axis = 1)\n",
    "\n",
    "    ## FILL NA FOR LAG MONTH\n",
    "    thresh_hold = np.min(modelling_data.ngay_giao)\n",
    "    fill_data =[]\n",
    "    null_demand_lag_month = demand_lag_month[(demand_lag_month.demand).isnull()]\n",
    "    for index,row in null_demand_lag_month.iterrows():\n",
    "        d = row[\"ngay_ca_1\"]\n",
    "        d = subtract_month(d)\n",
    "        available_data = np.nan\n",
    "        while get_date(d) > thresh_hold and math.isnan(available_data):\n",
    "            try:\n",
    "                available_data = modelling_data.demand.loc[d]\n",
    "            except:\n",
    "                available_data = np.nan\n",
    "            d = subtract_month(d)\n",
    "        fill_data.append(available_data)    \n",
    "    null_demand_lag_month['fill_data'] = fill_data\n",
    "    fill_data = null_demand_lag_month['fill_data']\n",
    "    fill_data = fill_data.reset_index()\n",
    "    demand_lag_month = demand_lag_month.reset_index()\n",
    "    demand_lag_month = pd.merge(demand_lag_month, fill_data, how=\"left\", on=\"ngay_ca\")\n",
    "    demand_lag_month = demand_lag_month.set_index(\"ngay_ca\")\n",
    "    demand_lag_month = demand_lag_month.apply(fill_na_custom, axis = 1)\n",
    "\n",
    "    ## Fill NA for lag day:\n",
    "    thresh_hold = np.min(modelling_data.ngay_giao)\n",
    "    fill_data =[]\n",
    "    null_demand_lag_day = demand_lag_day[(demand_lag_day.demand).isnull()]\n",
    "    for index,row in null_demand_lag_day.iterrows():\n",
    "        d = row[\"ngay_ca_1\"]\n",
    "        d = subtract_day(d)\n",
    "        available_data = np.nan\n",
    "        while get_date(d) > thresh_hold and math.isnan(available_data):\n",
    "            try:\n",
    "                available_data = modelling_data.demand.loc[d]\n",
    "            except:\n",
    "                available_data = np.nan\n",
    "            d = subtract_day(d)\n",
    "        fill_data.append(available_data)    \n",
    "    null_demand_lag_day['fill_data'] = fill_data\n",
    "    fill_data = null_demand_lag_day['fill_data']\n",
    "    fill_data = fill_data.reset_index()\n",
    "    demand_lag_day = demand_lag_day.reset_index()\n",
    "    demand_lag_day = pd.merge(demand_lag_day, fill_data, how=\"left\", on=\"ngay_ca\")\n",
    "    demand_lag_day = demand_lag_day.set_index(\"ngay_ca\")\n",
    "    demand_lag_day = demand_lag_day.apply(fill_na_custom, axis = 1)\n",
    "    modelling_data[\"demand_lag_week\"] = demand_lag_week['demand']\n",
    "    modelling_data[\"demand_lag_2week\"] = demand_lag_2week['demand']\n",
    "    modelling_data[\"demand_lag_3week\"] = demand_lag_3week['demand']\n",
    "    modelling_data['ma_week'] = np.nanmean(modelling_data[['demand_lag_week', 'demand_lag_2week', 'demand_lag_3week']], axis = 1)\n",
    "    modelling_data[\"demand_lag_month\"] = demand_lag_month['demand']\n",
    "    modelling_data[\"demand_lag_day\"] = demand_lag_day['demand']\n",
    "    modelling_data['demand_lag_ca1'] = demand_lag_ca1['demand']\n",
    "    modelling_data['numDays'] = (modelling_data.ngay_giao -  pd.to_datetime('1/1/2018'))/np.timedelta64(1, 'D') \n",
    "    modelling_data['dow'] = modelling_data.ngay_giao.dt.dayofweek\n",
    "    model_data.append(modelling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## làm mô hình cho ca 1 riêng cho kết quả tốt hơn\n",
    "## Lam mo hinh cho tung ngay trong tuan\n",
    "model_dict = {}\n",
    "locs = ['HN',\"HCM\"]\n",
    "for i in range(len(model_data)):\n",
    "    model_data_ = model_data[i]\n",
    "    for e in range(4):\n",
    "        for j in range(7):\n",
    "            temp = model_data_[model_data_.dow == j]\n",
    "            X_y = temp[['ma_week',\"numDays\",\"demand_lag_week\", \"demand_lag_month\",\"before_holiday\",\"new_users\",'sales','demand']]\n",
    "            X_y = X_y.dropna()\n",
    "            X_ = X_y[[\"numDays\",\"demand_lag_week\", \"demand_lag_month\",\"before_holiday\",\"new_users\",'sales']]\n",
    "            y_ = X_y['demand']\n",
    "            X = X_[X_.index.str[-1]=='{}'.format(e)]\n",
    "            y = y_[y_.index.str[-1]=='{}'.format(e)]\n",
    "            performance = 10000\n",
    "            mod = 0\n",
    "            X_1, X_test, y_1, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "            X_train, X_valid, y_train, y_valid = train_test_split(X_1, y_1, test_size = 0.2)\n",
    "            alphas = [0.01, 0.1, 0.3, 0.5, 0.8]\n",
    "            for alpha in alphas:\n",
    "                model = linear_model.Lasso(alpha = alpha, normalize=True)\n",
    "                model.fit(X_train, y_train)\n",
    "                per = model.score(X_valid, y_valid)\n",
    "                if per < performance:\n",
    "                    performance = per\n",
    "                    mod = model\n",
    "                    # print(alpha)\n",
    "            performance = model.score(X_test, y_test)\n",
    "            model_dict['{0}_{1}_{2}'.format(locs[i], e, j)] = [mod, performance]\n",
    "\n",
    "model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday_date(date):\n",
    "    if date in holidays:\n",
    "        return 0\n",
    "    for i in range(6): \n",
    "        res = 0\n",
    "        if date + np.timedelta64(i,\"D\") in holidays and date + np.timedelta64(i, \"D\") not in sundays:\n",
    "            res= 7-i\n",
    "            break\n",
    "    return res\n",
    "\n",
    "result = pd.read_csv(\"shippo_forecast_week.csv\", header = None)\n",
    "result[0] = pd.to_datetime(result[0])\n",
    "result = result[np.logical_and(result[0]<=pd.Timestamp.today() - pd.DateOffset(n=1), result[0]>pd.Timestamp.today() - pd.DateOffset(n=10))]\n",
    "result.to_csv(\"shippo_forecast_week.csv\", header=False, index=False)\n",
    "# os.remove('shippo_forecast_week.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(13):    \n",
    "    current_date = np.datetime64(datetime.datetime.now().strftime(\"%Y-%m-%d\")) + np.timedelta64(m)\n",
    "    numDays = (pd.to_datetime(current_date) -  pd.to_datetime('1/1/2018'))/np.timedelta64(1, 'D') \n",
    "    last_week = np.datetime64(pd.to_datetime(current_date) - pd.DateOffset(days = 7),'D')\n",
    "    last_2week = np.datetime64(pd.to_datetime(current_date) - pd.DateOffset(days = 14),'D')\n",
    "    last_3week = np.datetime64(pd.to_datetime(current_date) - pd.DateOffset(days = 21),'D')\n",
    "    last_month = np.datetime64(pd.to_datetime(current_date) - pd.DateOffset(months = 1),'D')\n",
    "    dow = pd.to_datetime(current_date).weekday()\n",
    "    hol = holiday_date(np.datetime64(pd.to_datetime(current_date)))\n",
    "    new_user = get_new_users_last_month(pd.to_datetime(current_date))\n",
    "    with open(\"shippo_forecast_week.csv\",'a+') as file:\n",
    "        for i in range(2):\n",
    "            temp = pd.to_datetime(current_date)\n",
    "            se = salesman.iloc[i]['{}-{}'.format(temp.year, temp.month)]\n",
    "            for j in range(4):\n",
    "                lag_week = np.nan\n",
    "                lag_month = np.nan\n",
    "                temp_month = last_month\n",
    "                temp_week = last_week\n",
    "                thresh_hold = np.min(model_data[i].ngay_giao)\n",
    "                lag_1week = demand_dicts[i].get(pd.to_datetime(last_week).strftime(\"%m%d%Y\") + '{}'.format(j), np.nan)\n",
    "                lag_2week = demand_dicts[i].get(pd.to_datetime(last_2week).strftime(\"%m%d%Y\") + '{}'.format(j), np.nan)\n",
    "                lag_3week = demand_dicts[i].get(pd.to_datetime(last_3week).strftime(\"%m%d%Y\") + '{}'.format(j), np.nan)\n",
    "                ma_week = np.nanmean([lag_1week, lag_2week, lag_3week])\n",
    "                while pd.to_datetime(temp_week) > thresh_hold and math.isnan(lag_week):\n",
    "                    try:\n",
    "                        lag_week = demand_dicts[i][pd.to_datetime(temp_week).strftime(\"%m%d%Y\") + '{}'.format(j)]\n",
    "                    except:\n",
    "                        lag_week = np.nan\n",
    "                    temp_week = np.datetime64(pd.to_datetime(temp_week) - pd.DateOffset(days = 7),'D')\n",
    "                while pd.to_datetime(temp_month) > thresh_hold and math.isnan(lag_month):\n",
    "                    try:\n",
    "                        lag_month = demand_dicts[i][pd.to_datetime(temp_month).strftime(\"%m%d%Y\") + '{}'.format(j)]\n",
    "                    except:\n",
    "                        lag_month = np.nan\n",
    "                    temp_month = np.datetime64(pd.to_datetime(temp_month) - pd.DateOffset(months = 1),'D')\n",
    "\n",
    "                model = model_dict['{}_{}_{}'.format(locs[i], j, dow)][0]\n",
    "                inp = np.array([ numDays, lag_week, lag_month, hol, new_user, se]).reshape(1, -1)\n",
    "                try:\n",
    "                    res = model.predict(inp)\n",
    "                except:\n",
    "                    res = \"Not enough information\"\n",
    "                with open(\"shippo_forecast_week.csv\",'a+') as file:\n",
    "                    try:\n",
    "                        file.write(\"{}, {} ca {}, {}, {}\\n\".format(current_date, locs[i], j, float(res),  model_dict['{}_{}_{}'.format(locs[i], j, dow)][1]))\n",
    "                    except:\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastNightSql = 'Select \"deliverFromProvinceId\", count(id) from public.\"DeliveryOrder\"\\\n",
    "where \"createdTime\" + interval \\'7 hours\\'> Date(now() + interval \\'7 hours\\' - interval \\'1 days\\') + interval \\'19 hours\\'\\\n",
    "and \"createdTime\" + interval \\'7 hours\\'< Date(now() + interval \\'7 hours\\') + interval \\'6 hours\\'\\\n",
    "group by \"deliverFromProvinceId\"'\n",
    "\n",
    "actualLastNight = pd.read_sql_query(lastNightSql, connection)\n",
    "actualLastNight = actualLastNight.replace({9: \" HN ca 0\", 80: \" HCM ca 0\"})\n",
    "actualLastNight['Date'] =  pd.to_datetime(np.datetime64(pd.Timestamp.today().date()))\n",
    "forecast_week = pd.read_csv('shippo_forecast_week.csv', header = None)\n",
    "forecast_week[0] = pd.to_datetime(forecast_week[0])\n",
    "temp = forecast_week.merge(actualLastNight, how='left', left_on=[0, 1],right_on = ['Date', 'deliverFromProvinceId'])\n",
    "\n",
    "def addActual(row):\n",
    "    if row[0] == np.datetime64(pd.Timestamp.today().date()):\n",
    "        if row[1].endswith('0'):\n",
    "            row['adjusted'] = row['count']\n",
    "        else:\n",
    "            row['adjusted'] = row[2]\n",
    "    else:\n",
    "        row['adjusted'] = row[2]\n",
    "    return row\n",
    "temp = temp.apply(addActual, axis = 1)\n",
    "temp = temp[[0,1,'adjusted',3]]\n",
    "temp.to_csv(\"shippo_forecast_week.csv\", header=False, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
